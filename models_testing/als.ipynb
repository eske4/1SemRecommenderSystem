{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# spark imports\n",
    "import sys\n",
    "import pyspark\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# data science imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# recommenders imports\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.evaluation.spark_evaluation import SparkRankingEvaluation, SparkDiversityEvaluation\n",
    "from recommenders.utils.spark_utils import start_or_get_spark\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.9.20 (main, Oct  3 2024, 07:27:41) \n",
      "[GCC 11.2.0]\n",
      "Spark version: 3.5.3\n"
     ]
    }
   ],
   "source": [
    "print(f\"System version: {sys.version}\")\n",
    "print(\"Spark version: {}\".format(pyspark.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 50\n",
    "\n",
    "# Column names for the dataset\n",
    "COL_USER = \"user_id\"\n",
    "COL_TRACK = \"track_id\"\n",
    "COL_COUNT = \"playcount\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/02 14:45:25 WARN Utils: Your hostname, schade-Asus-Vivobook resolves to a loopback address: 127.0.1.1; using 192.168.87.180 instead (on interface wlo1)\n",
      "24/12/02 14:45:25 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/02 14:45:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/12/02 14:45:27 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    }
   ],
   "source": [
    "# the following settings work well for debugging locally on VM - change when running on a cluster\n",
    "# set up a giant single executor with many threads and specify memory cap\n",
    "spark = start_or_get_spark(\"ALS PySpark\", memory=\"16g\", config={'spark.local.dir': \"/home/matildeschade/spark-temp\", 'spark.cleaner.ttl': \"true\"})\n",
    "spark.conf.set(\"spark.sql.analyzer.failAmbiguousSelfJoin\", \"false\")\n",
    "\n",
    "spark.catalog.clearCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+\n",
      "|user_id|track_id|playcount|\n",
      "+-------+--------+---------+\n",
      "|373    |11156   |3        |\n",
      "|844    |659     |1        |\n",
      "+-------+--------+---------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-------+--------+---------+\n",
      "|user_id|track_id|playcount|\n",
      "+-------+--------+---------+\n",
      "|76     |30993   |1        |\n",
      "|121    |43554   |3        |\n",
      "+-------+--------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in the dataset into pyspark DataFrame    \n",
    "test_listening_history = spark.read.option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \"\\t\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"../remappings/data/dataset/test_listening_history_OverEqual_50_Interactions.txt\")\n",
    "    \n",
    "train_listening_history = spark.read.option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \"\\t\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"../remappings/data/dataset/train_listening_history_OverEqual_50_Interactions.txt\")\n",
    "\n",
    "# Change columns to correct place (user_id, track_id, playcount)\n",
    "test_listening_history = test_listening_history.withColumn(\"track_id_temp\", test_listening_history.track_id).withColumn(\"user_id_temp\", test_listening_history.user_id)\n",
    "test_listening_history = test_listening_history.withColumn(\"track_id\", test_listening_history.user_id_temp).withColumn(\"user_id\", test_listening_history.track_id_temp)\n",
    "\n",
    "train_listening_history = train_listening_history.withColumn(\"track_id_temp\", train_listening_history.track_id).withColumn(\"user_id_temp\", train_listening_history.user_id)\n",
    "train_listening_history = train_listening_history.withColumn(\"track_id\", train_listening_history.user_id_temp).withColumn(\"user_id\", train_listening_history.track_id_temp)\n",
    "\n",
    "# key = old column, value = new column\n",
    "mapping = {\n",
    "    \"track_id\": COL_USER,\n",
    "    \"user_id\": COL_TRACK,\n",
    "    \"playcount\": COL_COUNT\n",
    "}\n",
    "\n",
    "test_listening_history = test_listening_history.select(*[F.col(old).alias(new) for old, new in mapping.items()])\n",
    "train_listening_history = train_listening_history.select(*[F.col(old).alias(new) for old, new in mapping.items()])\n",
    "\n",
    "# Sample\n",
    "test_listening_history = test_listening_history.sample(False, 0.005, 0)\n",
    "train_listening_history = train_listening_history.sample(False, 0.005, 0)\n",
    "\n",
    "test_listening_history.show(2, truncate=False)\n",
    "train_listening_history.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N train 7090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N test 1791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train, test = train_listening_history, test_listening_history\n",
    "\n",
    "# alpha = 1 \n",
    "\n",
    "# # Transform playcount to confidence using the current alpha\n",
    "# train = train.withColumn(\"confidence\", 1 + alpha * F.log(1 + F.col(COL_COUNT))).drop(COL_COUNT)\n",
    "\n",
    "# train.show(10, truncate=False)\n",
    "\n",
    "print (\"N train\", train.cache().count())\n",
    "print (\"N test\", test.cache().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train de ALS model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify ALS hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [10, 20, 30, 40]\n",
    "maxIters = [10, 20, 30, 40]\n",
    "regParams = [.05, .1, .15]\n",
    "alphas = [20, 40, 60, 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ALS_73cb934327f5, ALS_f66da5d08785, ALS_9eb6344fd317, ALS_e11e3f207bbd, ALS_bd3247c2d7b5, ALS_66a817b20253, ALS_4165d5a51b64, ALS_b51a3076485e, ALS_81db86f9a199, ALS_c5be940d0438, ALS_eef8e4625a1b, ALS_0ee54647deff, ALS_d5d9654d9669, ALS_2ddacbda7610, ALS_cfe34f4c9c84, ALS_d24453354e6d, ALS_264033ef5981, ALS_86a2767ff4e2, ALS_aa1af09a564f, ALS_fa1608686259, ALS_b116e537a895, ALS_4ab0dd476e4a, ALS_e6a171fef842, ALS_1f915a004178, ALS_3878c02f8d0d, ALS_3cd719664d21, ALS_563f9102118c, ALS_a66b0b85ad83, ALS_ca99df918f9d, ALS_a278c32840cf, ALS_e763bdc16e4c, ALS_8c4eb49d5bd9, ALS_3c6681192d4b, ALS_6281c3c21447, ALS_1fa7b056a2ce, ALS_96acb33fc150, ALS_07917ab4c5b8, ALS_eddae49176fc, ALS_da37ad8e1b25, ALS_d9dcfcc176a4, ALS_8451f5fb3e9a, ALS_b8547cbf7575, ALS_e907695eb4c5, ALS_6a2bf350b51d, ALS_c719a8bdfad2, ALS_9ff4dc13687d, ALS_50a6021f8657, ALS_e1c4c6ed041c, ALS_7dccc45927e5, ALS_62f57638d794, ALS_a82d5f4f9b9e, ALS_37227e5322ff, ALS_c2360e045a79, ALS_4d8050189d89, ALS_c634285a44c1, ALS_1a6c43ba3e41, ALS_dc7bf4b156ac, ALS_5747ddf6c6b6, ALS_b9a457442427, ALS_79ca44cc2046, ALS_4478fbca7f26, ALS_1f27fd9f0256, ALS_d8bcd4124dea, ALS_820595803699, ALS_9944c189d6ef, ALS_5581d6633eb3, ALS_767521d58823, ALS_fb526f5ea5b6, ALS_df51a63398d8, ALS_1e1fe5e7fa48, ALS_2f63750ff95e, ALS_6eb759fdd7ae, ALS_5000bd3d26c0, ALS_0b0715c7b4b7, ALS_fa61c88d9b3e, ALS_25ce9f38623d, ALS_9fd9541f9e63, ALS_1ae99e20648c, ALS_b981f91e09f4, ALS_aa9c91111e10, ALS_ddb4d9d2a6cd, ALS_e3612b86cb62, ALS_b54b44222d0f, ALS_1890ea6d62b7, ALS_48d8ff6efab5, ALS_7695f5efa9fc, ALS_9a9993255e6c, ALS_608385aad0a2, ALS_4d7f4073979e, ALS_26816b4c5aab, ALS_9519bdd082ef, ALS_ad4b3bf031de, ALS_7b445e2d224b, ALS_e18f8d7515c3, ALS_fc0153640834, ALS_58fd3360474b, ALS_913b051f6d68, ALS_8be400c6ad19, ALS_568297fb6388, ALS_55ca761e27ef, ALS_05447f492144, ALS_654f80929d34, ALS_8d02126066c9, ALS_477c3c7267dd, ALS_12befb1c52a1, ALS_1dac86dd4a4b, ALS_443ff4a5826f, ALS_a573d88768ad, ALS_78b3defb92c6, ALS_55839eadc331, ALS_cd95f24287c1, ALS_65af7e474e73, ALS_13fc02a79252, ALS_3f98ef21bfc9, ALS_db5a311ab152, ALS_91cedc43d736, ALS_9389dee6b74a, ALS_764ba37ed573, ALS_714ff856d204, ALS_ecf4edaa554a, ALS_a3517a6cb587, ALS_c39abdb2254c, ALS_045ced323cec, ALS_d681d2f1d042, ALS_b49cd9368b7d, ALS_2ee78d8b82bc, ALS_bddac7cc907c, ALS_aa773bf4b2a2, ALS_e7fdb9cd396b, ALS_5beab32b6000, ALS_2e0d007e3949, ALS_ce16b7e53ad4, ALS_51921eea942a, ALS_8b974a8c2e66, ALS_85a6c20cc454, ALS_143d42495a3d, ALS_081a28403c5f, ALS_942c5d7ddb46, ALS_5a88e519adfc, ALS_77f55f48482a, ALS_a5054c525beb, ALS_e6231a86a53f, ALS_d5abbd42f503, ALS_41858f461d5b, ALS_ac1082144baf, ALS_a3a5bdfa3933, ALS_8b30bfbeecea, ALS_1ebf8129f19b, ALS_19489b499ea6, ALS_29116f9ff7c7, ALS_870da0a21284, ALS_d932c585fb9d, ALS_22dc7bd98506, ALS_1b931a131707, ALS_2e1348039f4a, ALS_cf069a26b55d, ALS_f875d5b125c0, ALS_86c438cee58b, ALS_875d5afabe04, ALS_cb94c699bbdf, ALS_3459eaf7991c, ALS_753658d4a7d9, ALS_020873a7e0d4, ALS_f8f03b8f25e7, ALS_07e096645b62, ALS_a9293108442d, ALS_34fb0820c2b2, ALS_89eaed7b178f, ALS_1c236ff2fcee, ALS_a19b7b213200, ALS_b48ac479176c, ALS_ed0977acc49d, ALS_10bd1ea974f6, ALS_aee877926b4c, ALS_dc3fe2c64ae0, ALS_f5aaacdbb8d7, ALS_c9329387fe90, ALS_4b74544bdeb8, ALS_6ad9640159dd, ALS_2d0f696f29ed, ALS_8e693f725ba5, ALS_4c166a390b42, ALS_52411872e345, ALS_c8544fe45e27, ALS_b511baaa1495, ALS_f88a4bc410bd, ALS_d0dc54867f29, ALS_6c52065ac963, ALS_7f614448cffc, ALS_21d927d01013, ALS_36e5a6bfa268, ALS_28befd4c140c] Length of model_list:  192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For loop will automatically create and store ALS models\n",
    "model_list = []\n",
    "\n",
    "for r in tqdm(ranks):\n",
    "    for mi in maxIters:\n",
    "        for rp in regParams:\n",
    "            for a in alphas:\n",
    "                model_list.append(ALS(userCol= COL_USER, itemCol= COL_TRACK, ratingCol=COL_COUNT, rank = r, maxIter = mi, regParam = rp, alpha = a, coldStartStrategy=\"drop\", nonnegative = True, implicitPrefs = True))\n",
    "\n",
    "# Print the model list, and the length of model_list\n",
    "print (model_list, \"Length of model_list: \", len(model_list))\n",
    "\n",
    "# Validate\n",
    "len(model_list) == (len(ranks)*len(maxIters)*len(regParams)*len(alphas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected percentile rank error metric function\n",
    "def ROEM(predictions, userCol = COL_USER, itemCol = COL_TRACK, ratingCol = COL_COUNT):\n",
    "  # Creates table that can be queried\n",
    "  predictions.createOrReplaceTempView(\"predictions\")\n",
    "  \n",
    "  # Sum of total number of plays of all songs\n",
    "  denominator = predictions.groupBy().sum(ratingCol).collect()[0][0]\n",
    "\n",
    "  # Calculating rankings of songs predictions by user\n",
    "  spark.sql(\"SELECT \" + userCol + \" , \" + ratingCol + \" , PERCENT_RANK() OVER (PARTITION BY \" + userCol + \" ORDER BY prediction DESC) AS rank FROM predictions\").createOrReplaceTempView(\"rankings\")\n",
    "\n",
    "  # Multiplies the rank of each song by the number of plays and adds the products together\n",
    "  numerator = spark.sql('SELECT SUM(' + ratingCol + ' * rank) FROM rankings').collect()[0][0]\n",
    "  performance = numerator/denominator\n",
    "  \n",
    "  return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Building 5 folds within the training set.\n",
    "# train1, train2, train3, train4, train5 = train.randomSplit([0.2, 0.2, 0.2, 0.2, 0.2], seed = 1)\n",
    "# fold1 = train2.union(train3).union(train4).union(train5)\n",
    "# fold2 = train3.union(train4).union(train5).union(train1)\n",
    "# fold3 = train4.union(train5).union(train1).union(train2)\n",
    "# fold4 = train5.union(train1).union(train2).union(train3)\n",
    "# fold5 = train1.union(train2).union(train3).union(train4)\n",
    "\n",
    "# foldlist = [(fold1, train1), (fold2, train2), (fold3, train3), (fold4, train4), (fold5, train5)]\n",
    "\n",
    "# # Empty list to fill with ROEMs from each model\n",
    "# ROEMS = []\n",
    "\n",
    "# # Loops through all models and all folds\n",
    "# for model in model_list:\n",
    "#     for ft_pair in foldlist:\n",
    "\n",
    "#         # Fits model to fold within training data\n",
    "#         fitted_model = model.fit(ft_pair[0])\n",
    "\n",
    "#         # Generates predictions using fitted_model on respective CV test data\n",
    "#         predictions = fitted_model.transform(ft_pair[1])\n",
    "\n",
    "#         # Generates and prints a ROEM metric CV test data\n",
    "#         r = ROEM(predictions)\n",
    "#         print (\"ROEM: \", r)\n",
    "\n",
    "#     # Fits model to all of training data and generates preds for test data\n",
    "#     v_fitted_model = model.fit(train)\n",
    "#     v_predictions = v_fitted_model.transform(test)\n",
    "#     v_ROEM = ROEM(v_predictions)\n",
    "\n",
    "#     # Adds validation ROEM to ROEM list\n",
    "#     ROEMS.append(v_ROEM)\n",
    "#     print (\"Validation ROEM: \", v_ROEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank:  10\n",
      "MaxIter:  40\n",
      "RegParam:  0.05\n",
      "Alpha:  60.0\n"
     ]
    }
   ],
   "source": [
    "# Extract the best_model\n",
    "best_model = model_list[38]\n",
    "\n",
    "# Extract the Rank\n",
    "best_rank = best_model.getRank()\n",
    "print (\"Rank: \", best_rank)\n",
    "\n",
    "# Extract the MaxIter value\n",
    "best_maxIter = best_model.getMaxIter()\n",
    "print (\"MaxIter: \", best_maxIter)\n",
    "\n",
    "# Extract the RegParam value\n",
    "best_regParam = best_model.getRegParam()\n",
    "print (\"RegParam: \", best_regParam)\n",
    "\n",
    "# Extract the Alpha value\n",
    "best_alpha = best_model.getAlpha()\n",
    "print (\"Alpha: \", best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# header = {\n",
    "#     \"userCol\": COL_USER,\n",
    "#     \"itemCol\": COL_TRACK,\n",
    "#     \"ratingCol\": 'confidence',\n",
    "# }\n",
    "\n",
    "# als = ALS(\n",
    "#     rank=best_rank,\n",
    "#     maxIter=best_maxIter,\n",
    "#     implicitPrefs=True,\n",
    "#     regParam=best_regParam,\n",
    "#     alpha=best_alpha,\n",
    "#     coldStartStrategy='drop',\n",
    "#     nonnegative=True,\n",
    "#     seed=42,\n",
    "#     **header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/02 14:45:52 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/12/02 14:45:52 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 24.439710680000076 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    model = best_model.fit(train)\n",
    "\n",
    "print(\"Took {} seconds for training.\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/02 14:46:15 WARN Column: Constructing trivially true equals predicate, 'user_id#100 = user_id#100'. Perhaps you need to use aliases.\n",
      "24/12/02 14:46:15 WARN Column: Constructing trivially true equals predicate, 'track_id#101 = track_id#101'. Perhaps you need to use aliases.\n",
      "[Stage 3771:==============================================>     (177 + 8) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 101.23276237799996 seconds for prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "with Timer() as test_time:\n",
    "\n",
    "    # Get the cross join of all user-item pairs and score them.\n",
    "    users = train.select(COL_USER).distinct()\n",
    "    items = train.select(COL_TRACK).distinct()\n",
    "    user_item = users.crossJoin(items)\n",
    "    dfs_pred = model.transform(user_item)\n",
    "\n",
    "    # Remove seen items.\n",
    "    dfs_pred_exclude_train = dfs_pred.alias(\"pred\").join(\n",
    "        train.alias(\"train\"),\n",
    "        (dfs_pred[COL_USER] == train[COL_USER]) & (dfs_pred[COL_TRACK] == train[COL_TRACK]),\n",
    "        how='outer'\n",
    "    )\n",
    "\n",
    "    top_all = dfs_pred_exclude_train.filter(dfs_pred_exclude_train[f\"train.{COL_COUNT}\"].isNull()) \\\n",
    "        .select('pred.' + COL_USER, 'pred.' + COL_TRACK, 'pred.' + \"prediction\")\n",
    "\n",
    "    # In Spark, transformations are lazy evaluation\n",
    "    # Use an action to force execute and measure the test time \n",
    "    top_all.cache().count()\n",
    "\n",
    "print(\"Took {} seconds for prediction.\".format(test_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+----------+\n",
      "|user_id|track_id|prediction|\n",
      "+-------+--------+----------+\n",
      "|     76|     981|       0.0|\n",
      "|     76|    1846|       0.0|\n",
      "|     76|    5574|  1.144651|\n",
      "|     76|   11896|       0.0|\n",
      "|     76|   13210| 1.3216627|\n",
      "|     76|   14016|       0.0|\n",
      "|     76|   19932|       0.0|\n",
      "|     76|   20577|       0.0|\n",
      "|     76|   22155|       0.0|\n",
      "|     76|   22187|       0.0|\n",
      "|     76|   22899|       0.0|\n",
      "|     76|   24023| 1.2022697|\n",
      "|     76|   24634|       0.0|\n",
      "|     76|   25595|       0.0|\n",
      "|     76|   29823|       0.0|\n",
      "|     76|   31088|       0.0|\n",
      "|     76|   36593|       0.0|\n",
      "|     76|   39351|       0.0|\n",
      "|     76|   40617|       0.0|\n",
      "|    121|     625|       0.0|\n",
      "+-------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_all.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3864:===================================================> (97 + 3) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|user_id|     recommendations|\n",
      "+-------+--------------------+\n",
      "|     76|[{5610, 3.2195482...|\n",
      "|    667|[{2629, 4.5185795...|\n",
      "|    844|[{1939, 2.989554}...|\n",
      "|   2962|[{4788, 2.0995054...|\n",
      "|   3242|[{5692, 3.9883537...|\n",
      "|   5695|[{5610, 1.1986922...|\n",
      "|   6962|[{1939, 1.0460057...|\n",
      "|  10011|[{3521, 0.0}, {33...|\n",
      "|  14058|[{2687, 3.7338943...|\n",
      "|  14525|[{3521, 0.0}, {33...|\n",
      "+-------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# top_k_rec = model.recommendForAllUsers(TOP_K)\n",
    "# top_k_rec.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with Timer() as t:\n",
    "#     predictions = model.transform(test)\n",
    "# print(\"Took {} seconds for prediction.\".format(t))\n",
    "\n",
    "# predictions.cache().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rank_eval = SparkRankingEvaluation(test, top_all, k = TOP_K, col_user=COL_USER, col_item=COL_TRACK, \n",
    "                                    col_rating=COL_COUNT, col_prediction=\"prediction\", relevancy_method=\"top_k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3981:=================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\tALS\n",
      "Precision@K:\t0.000254\n",
      "Recall@K:\t0.012685\n",
      "NDCG:\t0.003078\n",
      "MAP:\t0.000828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Model:\\tALS\",\n",
    "      \"Precision@K:\\t%f\" % rank_eval.precision_at_k(),\n",
    "      \"Recall@K:\\t%f\" % rank_eval.recall_at_k(), \n",
    "      \"NDCG:\\t%f\" % rank_eval.ndcg_at_k(),\n",
    "      \"MAP:\\t%f\" % rank_eval.map_at_k(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup spark instance\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsyskernel",
   "language": "python",
   "name": "recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
