{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# spark imports\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecommendation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ALS\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# spark imports\n",
    "import sys\n",
    "import pyspark\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import StringType, FloatType, IntegerType, LongType\n",
    "\n",
    "# data science imports\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# recommenders imports\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.utils.notebook_utils import is_jupyter\n",
    "from recommenders.datasets.spark_splitters import spark_random_split\n",
    "from recommenders.evaluation.spark_evaluation import SparkRatingEvaluation, SparkRankingEvaluation\n",
    "from recommenders.utils.spark_utils import start_or_get_spark\n",
    "from recommenders.utils.notebook_utils import store_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"System version: {sys.version}\")\n",
    "print(\"Spark version: {}\".format(pyspark.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Column names for the dataset\n",
    "COL_USER = \"user_id\"\n",
    "COL_TRACK = \"track_id\"\n",
    "COL_COUNT = \"playcount\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following settings work well for debugging locally on VM - change when running on a cluster\n",
    "# set up a giant single executor with many threads and specify memory cap\n",
    "spark = start_or_get_spark(\"ALS PySpark\", memory=\"16g\", config={'spark.local.dir': \"/home/manuel-albino/spark-temp\", 'spark.cleaner.ttl': \"true\"})\n",
    "spark.conf.set(\"spark.sql.analyzer.failAmbiguousSelfJoin\", \"false\")\n",
    "\n",
    "spark.catalog.clearCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataset into pyspark DataFrame\n",
    "song_ratings = spark.read.option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \"\\t\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"../remappings/data/Modified_Listening_History.txt\")\n",
    "\n",
    "#remapping\n",
    "song_ratings = song_ratings.withColumn(\"track_id_temp\", song_ratings.track_id).withColumn(\"user_id_temp\", song_ratings.user_id)\n",
    "\n",
    "song_ratings = song_ratings.withColumn(\"track_id\", song_ratings.user_id_temp).withColumn(\"user_id\", song_ratings.track_id_temp)\n",
    "\n",
    "# key = old column, value = new column\n",
    "mapping = {\n",
    "    \"track_id\": COL_USER,\n",
    "    \"user_id\": COL_TRACK,\n",
    "    \"playcount\": COL_COUNT\n",
    "}\n",
    "\n",
    "song_ratings = song_ratings.select(*[F.col(old).alias(new) for old, new in mapping.items()])\n",
    "sample = song_ratings.sample(False, 0.01, 0)\n",
    "\n",
    "# show matrix (track, user, playcount)\n",
    "sample.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = spark_random_split(sample, ratio=0.75, seed=123)\n",
    "print (\"N train\", train.cache().count())\n",
    "print (\"N test\", test.cache().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1 \n",
    "\n",
    "# Transform playcount to confidence using the current alpha\n",
    "train_with_confidence = train.withColumn(\"confidence\", 1 + alpha * F.log(1 + F.col(COL_COUNT)))\n",
    "\n",
    "header = {\n",
    "    \"userCol\": COL_USER,\n",
    "    \"itemCol\": COL_TRACK,\n",
    "    \"ratingCol\": \"confidence\",\n",
    "}\n",
    "\n",
    "als = ALS(\n",
    "    rank=10,\n",
    "    maxIter=15,\n",
    "    implicitPrefs=True,\n",
    "    regParam=0.05,\n",
    "    coldStartStrategy='drop',\n",
    "    nonnegative=False,\n",
    "    seed=42,\n",
    "    **header\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as train_time:\n",
    "    model = als.fit(train_with_confidence)\n",
    "\n",
    "print(\"Took {} seconds for training.\".format(train_time.interval))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as test_time:\n",
    "    # Get the distinct user and item columns\n",
    "    users = train.select(COL_USER).distinct()\n",
    "    items = train.select(COL_TRACK).distinct()\n",
    "    \n",
    "    # Perform a cross join to get all user-item pairs\n",
    "    user_item = users.crossJoin(items)\n",
    "\n",
    "    # Alias columns to ensure clarity during joins\n",
    "    dfs_pred = model.transform(user_item.alias(\"user_item\"))\n",
    "\n",
    "    # Exclude seen items by joining predictions with the training data\n",
    "    dfs_pred_exclude_train = dfs_pred.alias(\"pred\").join(\n",
    "        train.alias(\"train\"),\n",
    "        (F.col(\"pred.\" + COL_USER) == F.col(\"train.\" + COL_USER)) &\n",
    "        (F.col(\"pred.\" + COL_TRACK) == F.col(\"train.\" + COL_TRACK)),\n",
    "        how='left_outer'  # using left join to keep predictions\n",
    "    )\n",
    "\n",
    "    # Filter out items seen during training\n",
    "    top_all = dfs_pred_exclude_train.filter(F.col(\"train.\" + COL_COUNT).isNull()).select(\n",
    "        F.col(\"pred.\" + COL_USER).alias(COL_USER),\n",
    "        F.col(\"pred.\" + COL_TRACK).alias(COL_TRACK),\n",
    "        F.col(\"pred.prediction\").alias(\"prediction\")\n",
    "    )\n",
    "\n",
    "    # Trigger the evaluation with an action and cache the result for efficiency\n",
    "    top_all.cache().count()\n",
    "\n",
    "# Measure and print the time taken for the prediction process\n",
    "print(\"Took {} seconds for prediction.\".format(test_time.interval))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_all.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_eval = SparkRankingEvaluation(test, top_all, k = TOP_K, col_user=COL_USER, col_item=COL_TRACK, \n",
    "                                    col_rating=COL_COUNT, col_prediction=\"prediction\", \n",
    "                                    relevancy_method=\"top_k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model:\\tALS\",\n",
    "      \"Top K:\\t%d\" % rank_eval.k,\n",
    "      \"MAP:\\t%f\" % rank_eval.map_at_k(),\n",
    "      \"NDCG:\\t%f\" % rank_eval.ndcg_at_k(),\n",
    "      \"Precision@K:\\t%f\" % rank_eval.precision_at_k(),\n",
    "      \"Recall@K:\\t%f\" % rank_eval.recall_at_k(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predicted ratings.\n",
    "prediction = model.transform(test)\n",
    "prediction.cache().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_eval = SparkRatingEvaluation(test, prediction, col_user=COL_USER, col_item=COL_TRACK, \n",
    "                                    col_rating=COL_COUNT, col_prediction=\"prediction\")\n",
    "\n",
    "print(\"Model:\\tALS rating prediction\",\n",
    "      \"RMSE:\\t%f\" % rating_eval.rmse(),\n",
    "      \"MAE:\\t%f\" % rating_eval.mae(),\n",
    "      \"Explained variance:\\t%f\" % rating_eval.exp_var(),\n",
    "      \"R squared:\\t%f\" % rating_eval.rsquared(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup spark instance\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
