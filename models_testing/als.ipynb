{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# spark imports\n",
    "import sys\n",
    "import pyspark\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# data science imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# recommenders imports\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.evaluation.spark_evaluation import SparkRankingEvaluation, SparkDiversityEvaluation\n",
    "from recommenders.utils.spark_utils import start_or_get_spark\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.9.20 (main, Oct  3 2024, 07:27:41) \n",
      "[GCC 11.2.0]\n",
      "Spark version: 3.5.3\n"
     ]
    }
   ],
   "source": [
    "print(f\"System version: {sys.version}\")\n",
    "print(\"Spark version: {}\".format(pyspark.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 50\n",
    "\n",
    "# Column names for the dataset\n",
    "COL_USER = \"user_id\"\n",
    "COL_TRACK = \"track_id\"\n",
    "COL_COUNT = \"playcount\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/02 09:05:20 WARN Utils: Your hostname, schade-Asus-Vivobook resolves to a loopback address: 127.0.1.1; using 172.25.20.98 instead (on interface wlo1)\n",
      "24/12/02 09:05:20 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/02 09:05:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/12/02 09:05:21 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    }
   ],
   "source": [
    "# the following settings work well for debugging locally on VM - change when running on a cluster\n",
    "# set up a giant single executor with many threads and specify memory cap\n",
    "spark = start_or_get_spark(\"ALS PySpark\", memory=\"16g\", config={'spark.local.dir': \"/home/matildeschade/spark-temp\", 'spark.cleaner.ttl': \"true\"})\n",
    "spark.conf.set(\"spark.sql.analyzer.failAmbiguousSelfJoin\", \"false\")\n",
    "\n",
    "spark.catalog.clearCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+\n",
      "|user_id|track_id|playcount|\n",
      "+-------+--------+---------+\n",
      "|11     |12239   |1        |\n",
      "|212    |3001    |1        |\n",
      "+-------+--------+---------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-------+--------+---------+\n",
      "|user_id|track_id|playcount|\n",
      "+-------+--------+---------+\n",
      "|11     |5578    |1        |\n",
      "|15     |6991    |1        |\n",
      "+-------+--------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in the dataset into pyspark DataFrame    \n",
    "test_listening_history = spark.read.option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \"\\t\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"../remappings/data/dataset/test_listening_history_OverEqual_50_Interactions.txt\")\n",
    "    \n",
    "train_listening_history = spark.read.option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \"\\t\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"../remappings/data/dataset/train_listening_history_OverEqual_50_Interactions.txt\")\n",
    "\n",
    "# Change columns to correct place (user_id, track_id, playcount)\n",
    "test_listening_history = test_listening_history.withColumn(\"track_id_temp\", test_listening_history.track_id).withColumn(\"user_id_temp\", test_listening_history.user_id)\n",
    "test_listening_history = test_listening_history.withColumn(\"track_id\", test_listening_history.user_id_temp).withColumn(\"user_id\", test_listening_history.track_id_temp)\n",
    "\n",
    "train_listening_history = train_listening_history.withColumn(\"track_id_temp\", train_listening_history.track_id).withColumn(\"user_id_temp\", train_listening_history.user_id)\n",
    "train_listening_history = train_listening_history.withColumn(\"track_id\", train_listening_history.user_id_temp).withColumn(\"user_id\", train_listening_history.track_id_temp)\n",
    "\n",
    "# key = old column, value = new column\n",
    "mapping = {\n",
    "    \"track_id\": COL_USER,\n",
    "    \"user_id\": COL_TRACK,\n",
    "    \"playcount\": COL_COUNT\n",
    "}\n",
    "\n",
    "test_listening_history = test_listening_history.select(*[F.col(old).alias(new) for old, new in mapping.items()])\n",
    "train_listening_history = train_listening_history.select(*[F.col(old).alias(new) for old, new in mapping.items()])\n",
    "\n",
    "# Sample\n",
    "test_listening_history = test_listening_history.sample(False, 0.01, 0)\n",
    "train_listening_history = train_listening_history.sample(False, 0.01, 0)\n",
    "\n",
    "test_listening_history.show(2, truncate=False)\n",
    "train_listening_history.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------------------+\n",
      "|user_id|track_id|confidence        |\n",
      "+-------+--------+------------------+\n",
      "|11     |5578    |1.6931471805599454|\n",
      "|15     |6991    |1.6931471805599454|\n",
      "|76     |30993   |1.6931471805599454|\n",
      "|121    |28093   |1.6931471805599454|\n",
      "|121    |43554   |2.386294361119891 |\n",
      "|142    |42504   |4.13549421592915  |\n",
      "|250    |18532   |1.6931471805599454|\n",
      "|328    |32483   |1.6931471805599454|\n",
      "|328    |11494   |1.6931471805599454|\n",
      "|337    |11916   |2.386294361119891 |\n",
      "+-------+--------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N train 14317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N test 3639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train, test = train_listening_history, test_listening_history\n",
    "\n",
    "alpha = 1 \n",
    "\n",
    "# Transform playcount to confidence using the current alpha\n",
    "train = train.withColumn(\"confidence\", 1 + alpha * F.log(1 + F.col(COL_COUNT))).drop(COL_COUNT)\n",
    "\n",
    "train.show(10, truncate=False)\n",
    "\n",
    "print (\"N train\", train.cache().count())\n",
    "print (\"N test\", test.cache().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train de ALS model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify ALS hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [10, 20, 30, 40]\n",
    "maxIters = [10, 20, 30, 40]\n",
    "regParams = [.05, .1, .15]\n",
    "alphas = [20, 40, 60, 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ALS_be57150ae4dc, ALS_ef10309223f4, ALS_5a775b6c0839, ALS_1cbd3312568e, ALS_880753c05b9c, ALS_0209bb0a6139, ALS_9b5707569849, ALS_51e7f91e1584, ALS_6a3ce187d718, ALS_632b39224f95, ALS_465a4430e159, ALS_eea0da4d22e7, ALS_624436777182, ALS_c136b7a2fbf2, ALS_4e4599410319, ALS_8d2cb218fa86, ALS_2af4e06f240e, ALS_18947d38971b, ALS_8b3fa8d1f945, ALS_4b189851dd7c, ALS_65973de2c39b, ALS_a6d53343678d, ALS_b14ce48726bb, ALS_27af8538bcaf, ALS_4ec886a8b06e, ALS_8c4ee0c8b365, ALS_bfeed325047b, ALS_4b5222dcdb0b, ALS_7a62191d0cda, ALS_e2548a469d4f, ALS_2f97c58d20d7, ALS_123a330726f6, ALS_477a9b609af6, ALS_c9fa3b645e57, ALS_497dec5f32a8, ALS_c80f4892997d, ALS_09fdbe212f0f, ALS_7ed2d0950d32, ALS_1decca6d44c2, ALS_898a21c5b1c0, ALS_f82c9c99f416, ALS_cb90dbba90c3, ALS_2cf3a0914c03, ALS_2403b888c957, ALS_7dac265ea674, ALS_430a6db66885, ALS_0bf6a4f9a9a7, ALS_e52c79d68db6, ALS_57024d23a682, ALS_db5950453b66, ALS_d575f07a262a, ALS_38bf61ae7d24, ALS_e2f39463cb91, ALS_5eb38797a33b, ALS_2301f9b01b2a, ALS_9c4cc4dfbceb, ALS_ff791f761040, ALS_4e91fb5de640, ALS_c4fa5da0c628, ALS_f7d5c7e60a8b, ALS_bfd746e8cff7, ALS_87bb80d5b330, ALS_dd6e5ea4ca61, ALS_e8e95379be40, ALS_1c27c8e0da61, ALS_5b082db81094, ALS_4cebaf485315, ALS_932526458cd3, ALS_e1b01e3fd952, ALS_755bbae91c41, ALS_edbec6332790, ALS_a74ce7186012, ALS_26deb78b4978, ALS_c7b4c4c05246, ALS_756dc8a49cd3, ALS_ae0a15b28c6f, ALS_2d4bf657e992, ALS_05076724b142, ALS_b8ca5c80aa61, ALS_d9cb08377ec0, ALS_91202f98f4d1, ALS_3e7d5e8396a4, ALS_983ab22ea440, ALS_44d9f97a3ea0, ALS_c777ff4c2861, ALS_6ce3b3fbb9e7, ALS_fb0b62475015, ALS_efbe2e92c533, ALS_22b3283ed9f0, ALS_cd1ffb15a242, ALS_4c4e42fb0595, ALS_36c690296d42, ALS_fd8510c23d62, ALS_f33f7fc272d1, ALS_b823a763cebc, ALS_8a8426a045e9, ALS_ab618d308dd2, ALS_3b23d7417e55, ALS_98bc6fb26a79, ALS_e8205675cb3e, ALS_ca41c769962e, ALS_f09b2bc0666b, ALS_b32cfe94545c, ALS_6063accc4505, ALS_0124743cf61e, ALS_8698d36c3202, ALS_538afa006f11, ALS_4cdd16a7b89f, ALS_47f09c447559, ALS_aac5458c78db, ALS_84adb6fbec0b, ALS_3da4db1f0d6e, ALS_2348ffd7b496, ALS_53cd2977a1ea, ALS_7514ff9cd187, ALS_e230eaa6fabe, ALS_366155f65dfc, ALS_8c039c7f06ba, ALS_c065b5ae0bd9, ALS_5cb2fe6ec1eb, ALS_8ad41759bb5d, ALS_368b511729c4, ALS_175e5bb8f3b4, ALS_916c8c506b2f, ALS_ff885922027e, ALS_b3afa5f6dda0, ALS_878fb7e2d1a4, ALS_3b245c43d551, ALS_44c2b6978a74, ALS_585a83aba9c2, ALS_4dfbd366c3ea, ALS_ba5d6a213b49, ALS_df6fff1768a1, ALS_4e8ebb7b8146, ALS_3109156275f5, ALS_e419a0cfd2b6, ALS_e18597983d48, ALS_f299ec647afb, ALS_6d6bd9fd5bad, ALS_6c11e94cc967, ALS_9621198d29fa, ALS_fa41648d8552, ALS_8e66fa96489a, ALS_a3676a425e7b, ALS_60b41b2b6ebe, ALS_1e8bc1f4a264, ALS_1002b4cbb1f2, ALS_15547e27c6f0, ALS_2d7bc2001d1f, ALS_db88181588f1, ALS_7d38deccb1f8, ALS_9fcca1cc3c84, ALS_2f830cdfdcfb, ALS_c1d299b82943, ALS_9c89c4ea9e9d, ALS_f6c042043968, ALS_4e118565b265, ALS_158489e0b157, ALS_3f8d19f7c11a, ALS_25c01331ae3e, ALS_4297a4c37796, ALS_e2e2918f1b42, ALS_9a04891c6725, ALS_5d126a216e96, ALS_3d3521f51298, ALS_fc6664cd0f7a, ALS_be316a72b3ba, ALS_ca6bd84f1f48, ALS_16d54b57902d, ALS_5a1709bc96e5, ALS_5f60f1975f64, ALS_d77d2b6fe118, ALS_830af1ebe027, ALS_88e56499f4ff, ALS_14bbab722194, ALS_4cd85273bd50, ALS_56040b136819, ALS_a9a600599f47, ALS_c411836db7de, ALS_f9a612695ec5, ALS_790cb51b2e64, ALS_e83c45719538, ALS_8503248071fe, ALS_fe33c8ed6010, ALS_aa8f565d54c5, ALS_8c6169d41072, ALS_280e46ac4d22, ALS_72aef041e253, ALS_7da5fff327d4, ALS_511cc95f87f5, ALS_28d9ff78e004, ALS_bf19dea96452] Length of model_list:  192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For loop will automatically create and store ALS models\n",
    "model_list = []\n",
    "\n",
    "for r in ranks:\n",
    "    for mi in maxIters:\n",
    "        for rp in regParams:\n",
    "            for a in alphas:\n",
    "                model_list.append(ALS(userCol= COL_USER, itemCol= COL_TRACK, ratingCol= COL_TRACK, rank = r, maxIter = mi, regParam = rp, alpha = a, coldStartStrategy=\"drop\", nonnegative = True, implicitPrefs = True))\n",
    "\n",
    "# Print the model list, and the length of model_list\n",
    "print (model_list, \"Length of model_list: \", len(model_list))\n",
    "\n",
    "# Validate\n",
    "len(model_list) == (len(ranks)*len(maxIters)*len(regParams)*len(alphas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected percentile rank error metric function\n",
    "def ROEM(predictions, userCol = COL_USER, itemCol = COL_TRACK, ratingCol = COL_COUNT):\n",
    "  # Creates table that can be queried\n",
    "  predictions.createOrReplaceTempView(\"predictions\")\n",
    "  \n",
    "  # Sum of total number of plays of all songs\n",
    "  denominator = predictions.groupBy().sum(ratingCol).collect()[0][0]\n",
    "\n",
    "  # Calculating rankings of songs predictions by user\n",
    "  spark.sql(\"SELECT \" + userCol + \" , \" + ratingCol + \" , PERCENT_RANK() OVER (PARTITION BY \" + userCol + \" ORDER BY prediction DESC) AS rank FROM predictions\").createOrReplaceTempView(\"rankings\")\n",
    "\n",
    "  # Multiplies the rank of each song by the number of plays and adds the products together\n",
    "  numerator = spark.sql('SELECT SUM(' + ratingCol + ' * rank) FROM rankings').collect()[0][0]\n",
    "  performance = numerator/denominator\n",
    "  \n",
    "  return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Building 5 folds within the training set.\n",
    "# train1, train2, train3, train4, train5 = train.randomSplit([0.2, 0.2, 0.2, 0.2, 0.2], seed = 1)\n",
    "# fold1 = train2.union(train3).union(train4).union(train5)\n",
    "# fold2 = train3.union(train4).union(train5).union(train1)\n",
    "# fold3 = train4.union(train5).union(train1).union(train2)\n",
    "# fold4 = train5.union(train1).union(train2).union(train3)\n",
    "# fold5 = train1.union(train2).union(train3).union(train4)\n",
    "\n",
    "# foldlist = [(fold1, train1), (fold2, train2), (fold3, train3), (fold4, train4), (fold5, train5)]\n",
    "\n",
    "# # Empty list to fill with ROEMs from each model\n",
    "# ROEMS = []\n",
    "\n",
    "# # Loops through all models and all folds\n",
    "# for model in model_list:\n",
    "#     for ft_pair in foldlist:\n",
    "\n",
    "#         # Fits model to fold within training data\n",
    "#         fitted_model = model.fit(ft_pair[0])\n",
    "\n",
    "#         # Generates predictions using fitted_model on respective CV test data\n",
    "#         predictions = fitted_model.transform(ft_pair[1])\n",
    "\n",
    "#         # Generates and prints a ROEM metric CV test data\n",
    "#         r = ROEM(predictions)\n",
    "#         print (\"ROEM: \", r)\n",
    "\n",
    "#     # Fits model to all of training data and generates preds for test data\n",
    "#     v_fitted_model = model.fit(train)\n",
    "#     v_predictions = v_fitted_model.transform(test)\n",
    "#     v_ROEM = ROEM(v_predictions)\n",
    "\n",
    "#     # Adds validation ROEM to ROEM list\n",
    "#     ROEMS.append(v_ROEM)\n",
    "#     print (\"Validation ROEM: \", v_ROEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank:  10\n",
      "MaxIter:  40\n",
      "RegParam:  0.05\n",
      "Alpha:  60.0\n"
     ]
    }
   ],
   "source": [
    "# Extract the best_model\n",
    "best_model = model_list[38]\n",
    "\n",
    "# Extract the Rank\n",
    "best_rank = best_model.getRank()\n",
    "print (\"Rank: \", best_rank)\n",
    "\n",
    "# Extract the MaxIter value\n",
    "best_maxIter = best_model.getMaxIter()\n",
    "print (\"MaxIter: \", best_maxIter)\n",
    "\n",
    "# Extract the RegParam value\n",
    "best_regParam = best_model.getRegParam()\n",
    "print (\"RegParam: \", best_regParam)\n",
    "\n",
    "# Extract the Alpha value\n",
    "best_alpha = best_model.getAlpha()\n",
    "print (\"Alpha: \", best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {\n",
    "    \"userCol\": COL_USER,\n",
    "    \"itemCol\": COL_TRACK,\n",
    "    \"ratingCol\": 'confidence',\n",
    "}\n",
    "\n",
    "als = ALS(\n",
    "    rank=best_rank,\n",
    "    maxIter=best_maxIter,\n",
    "    implicitPrefs=True,\n",
    "    regParam=best_regParam,\n",
    "    alpha=best_alpha,\n",
    "    coldStartStrategy='drop',\n",
    "    nonnegative=True,\n",
    "    seed=42,\n",
    "    **header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/02 09:05:45 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/12/02 09:05:45 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 40.26203268800009 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    model = als.fit(train)\n",
    "\n",
    "print(\"Took {} seconds for training.\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.1556 seconds for prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3842:==========================================>         (163 + 8) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+------------+\n",
      "|user_id|track_id|playcount|  prediction|\n",
      "+-------+--------+---------+------------+\n",
      "| 314281|    1484|        2|         0.0|\n",
      "| 400982|    8652|        1|         0.0|\n",
      "| 418759|   12891|        2|         0.0|\n",
      "| 504351|   34697|        1|         0.0|\n",
      "| 527042|    5192|        1|1.6201421E-6|\n",
      "| 534217|   21726|        1|         0.0|\n",
      "| 897873|   21442|        1|0.0040780953|\n",
      "|  28298|     112|        2|1.4247114E-6|\n",
      "| 425459|    2925|        1|         0.0|\n",
      "| 425459|    1063|        1|         0.0|\n",
      "| 552000|   14072|        1|         0.0|\n",
      "| 556666|   46612|        1|         0.0|\n",
      "|  22684|    5610|        4|         0.0|\n",
      "| 262341|     655|        1|         0.0|\n",
      "| 278907|   31402|        1|         0.0|\n",
      "| 415140|    2657|        1|2.3151435E-5|\n",
      "| 447922|    1042|        3|         0.0|\n",
      "| 798940|   12050|        1|         0.0|\n",
      "| 366105|   23630|        1|         0.0|\n",
      "| 366105|   48497|        1|         0.0|\n",
      "+-------+--------+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    prediction = model.transform(test)\n",
    "print(\"Took {} seconds for prediction.\".format(t))\n",
    "\n",
    "prediction.cache().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k recommendations for each user\n",
    "window = Window.partitionBy(COL_USER).orderBy(F.col(\"prediction\").desc())    \n",
    "\n",
    "top_k_reco = prediction.select(\"*\", F.row_number().over(window).alias(\"rank\")).filter(F.col(\"rank\") <= TOP_K).drop(\"rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rank_eval = SparkRankingEvaluation(test, prediction, k = TOP_K, col_user=COL_USER, col_item=COL_TRACK, \n",
    "                                    col_rating=COL_COUNT, col_prediction=\"prediction\", \n",
    "                                    relevancy_method=\"top_k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\tALS\n",
      "Precision@K:\t0.021597\n",
      "Recall@K:\t0.972130\n",
      "NDCG:\t0.978618\n",
      "MAP:\t0.972130\n"
     ]
    }
   ],
   "source": [
    "print(\"Model:\\tALS\",\n",
    "      \"Precision@K:\\t%f\" % rank_eval.precision_at_k(),\n",
    "      \"Recall@K:\\t%f\" % rank_eval.recall_at_k(), \n",
    "      \"NDCG:\\t%f\" % rank_eval.ndcg_at_k(),\n",
    "      \"MAP:\\t%f\" % rank_eval.map_at_k(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup spark instance\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsyskernel",
   "language": "python",
   "name": "recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
