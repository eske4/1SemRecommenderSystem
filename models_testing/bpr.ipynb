{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Personalized Ranking (BPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manuel-albino/miniconda3/envs/recsys/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.9.20 (main, Oct  3 2024, 07:27:41) \n",
      "[GCC 11.2.0]\n",
      "Cornac version: 1.18\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cornac\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from recommenders.evaluation.python_evaluation import map, ndcg_at_k, precision_at_k, recall_at_k, diversity, novelty\n",
    "from recommenders.models.cornac.cornac_utils import predict_ranking\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.utils.constants import SEED\n",
    "\n",
    "print(f\"System version: {sys.version}\")\n",
    "print(f\"Cornac version: {cornac.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 50\n",
    "\n",
    "# Model parameters\n",
    "NUM_FACTORS = 200\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "# Column names for the dataset\n",
    "COL_USER = \"user_id\"\n",
    "COL_TRACK = \"track_id\"\n",
    "COL_COUNT = \"playcount\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and split data\n",
    "\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         track_id  user_id  playcount\n",
      "0            3361       11          2\n",
      "1           15358       11          4\n",
      "2           17090       11          1\n",
      "3           11236       11          3\n",
      "4            9645       11          1\n",
      "...           ...      ...        ...\n",
      "1436854        43   962033          1\n",
      "1436855      1876   962033          4\n",
      "1436856      6382   962033          2\n",
      "1436857      2126   962033          1\n",
      "1436858       323   962033          4\n",
      "\n",
      "[1436859 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read from file\n",
    "test_listening_history = pd.read_csv(header=0, delimiter=\"\\t\", filepath_or_buffer=\"../remappings/data/dataset/test_listening_history_OverEqual_50_Interactions.txt\")\n",
    "train_listening_history = pd.read_csv(header=0, delimiter=\"\\t\", filepath_or_buffer=\"../remappings/data/dataset/train_listening_history_OverEqual_50_Interactions.txt\")\n",
    "\n",
    "# Change columns to correct place (user_id, track_id, playcount)\n",
    "track_test = test_listening_history[\"track_id\"]\n",
    "user_test = test_listening_history[\"user_id\"]\n",
    "\n",
    "track_train = train_listening_history[\"track_id\"]\n",
    "user_train = train_listening_history[\"user_id\"]\n",
    "\n",
    "test_listening_history[\"track_id\"] = user_test\n",
    "test_listening_history[\"user_id\"] = track_test\n",
    "\n",
    "train_listening_history[\"track_id\"] = user_train\n",
    "train_listening_history[\"user_id\"] = track_train\n",
    "\n",
    "test_listening_history.columns = [COL_USER, COL_TRACK, COL_COUNT]\n",
    "train_listening_history.columns = [COL_USER, COL_TRACK, COL_COUNT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_listening_history, test_listening_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Cornac Dataset\n",
    "\n",
    "To work with models implemented in Cornac, we need to construct an object from [Dataset](https://cornac.readthedocs.io/en/latest/data.html#module-cornac.data.dataset) class.\n",
    "\n",
    "Dataset Class in Cornac serves as the main object that the models will interact with.  In addition to data transformations, Dataset provides a bunch of useful iterators for looping through the data, as well as supporting different negative sampling techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_set \u001b[38;5;241m=\u001b[39m \u001b[43mcornac\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_uir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitertuples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSEED\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of users: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(train_set\u001b[38;5;241m.\u001b[39mnum_users))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of items: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(train_set\u001b[38;5;241m.\u001b[39mnum_items))\n",
      "File \u001b[0;32m~/miniconda3/envs/recsys/lib/python3.9/site-packages/cornac/data/dataset.py:386\u001b[0m, in \u001b[0;36mDataset.from_uir\u001b[0;34m(cls, data, seed)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_uir\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Constructing Dataset from UIR (User, Item, Rating) triplet data.\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    384\u001b[0m \n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUIR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/recsys/lib/python3.9/site-packages/cornac/data/dataset.py:319\u001b[0m, in \u001b[0;36mDataset.build\u001b[0;34m(cls, data, fmt, global_uid_map, global_iid_map, seed, exclude_unknowns)\u001b[0m\n\u001b[1;32m    316\u001b[0m ui_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()  \u001b[38;5;66;03m# avoid duplicate observations\u001b[39;00m\n\u001b[1;32m    317\u001b[0m dup_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 319\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (uid, iid, rating, \u001b[38;5;241m*\u001b[39m_) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exclude_unknowns \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    321\u001b[0m         uid \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m global_uid_map \u001b[38;5;129;01mor\u001b[39;00m iid \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m global_iid_map\n\u001b[1;32m    322\u001b[0m     ):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/recsys/lib/python3.9/collections/__init__.py:437\u001b[0m, in \u001b[0;36mnamedtuple.<locals>._make\u001b[0;34m(cls, iterable)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m defaults \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;21m__new__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__defaults__\u001b[39m \u001b[38;5;241m=\u001b[39m defaults\n\u001b[0;32m--> 437\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make\u001b[39m(\u001b[38;5;28mcls\u001b[39m, iterable):\n\u001b[1;32m    439\u001b[0m     result \u001b[38;5;241m=\u001b[39m tuple_new(\u001b[38;5;28mcls\u001b[39m, iterable)\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _len(result) \u001b[38;5;241m!=\u001b[39m num_fields:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_set = cornac.data.Dataset.from_uir(train.itertuples(index=False), seed=SEED)\n",
    "\n",
    "print('Number of users: {}'.format(train_set.num_users))\n",
    "print('Number of items: {}'.format(train_set.num_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the BPR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr = cornac.models.BPR(\n",
    "    k=NUM_FACTORS,\n",
    "    max_iter=NUM_EPOCHS,\n",
    "    learning_rate=0.01,\n",
    "    lambda_reg=0.001,\n",
    "    verbose=True,\n",
    "    seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    bpr.fit(train_set)\n",
    "print(\"Took {} seconds for training.\".format(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    all_predictions = predict_ranking(bpr, train, usercol=COL_USER, itemcol=COL_TRACK, remove_seen=True)\n",
    "print(\"Took {} seconds for prediction.\".format(t))\n",
    "\n",
    "all_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by 'user' and 'prediction' in descending order\n",
    "all_prediction_sorted = all_predictions.sort_values(by=[COL_USER, 'prediction'], ascending=[True, False])\n",
    "\n",
    "# Select the top k predictions for each user\n",
    "top_k_rec = all_prediction_sorted.groupby(COL_USER).head(TOP_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_map = map(test, top_k_rec, \n",
    "               col_user=COL_USER, \n",
    "               col_item=COL_TRACK, \n",
    "               col_prediction='prediction', \n",
    "               k=TOP_K,\n",
    "               relevancy_method=None)\n",
    "\n",
    "eval_ndcg = ndcg_at_k(test, top_k_rec, \n",
    "                      col_user=COL_USER, \n",
    "                      col_item=COL_TRACK, \n",
    "                      col_rating=COL_COUNT, \n",
    "                      col_prediction='prediction', \n",
    "                      k=TOP_K, \n",
    "                      relevancy_method=None)\n",
    "\n",
    "eval_precision = precision_at_k(test, top_k_rec, \n",
    "                                col_user=COL_USER, \n",
    "                                col_item=COL_TRACK, \n",
    "                                col_prediction='prediction', \n",
    "                                k=TOP_K, \n",
    "                                relevancy_method=None)\n",
    "\n",
    "eval_recall = recall_at_k(test, top_k_rec, \n",
    "                          col_user=COL_USER, \n",
    "                          col_item=COL_TRACK, \n",
    "                          col_prediction='prediction', \n",
    "                          k=TOP_K, \n",
    "                          relevancy_method=None)\n",
    "\n",
    "eval_diversity = diversity(train_df=train,\n",
    "                           reco_df=top_k_rec,\n",
    "                           col_user=COL_USER,\n",
    "                           col_item=COL_TRACK)\n",
    "\n",
    "eval_novelty = novelty(train_df=train,\n",
    "                       reco_df=top_k_rec,\n",
    "                       col_user=COL_USER,\n",
    "                       col_item=COL_TRACK)\n",
    "\n",
    "# Print evaluation metrics, including diversity\n",
    "print(\"Precision@K Spark:\\t%f\" % eval_precision,\n",
    "      \"Recall@K Spark:\\t%f\" % eval_recall,\n",
    "      \"NDCG Spark:\\t%f\" % eval_ndcg,\n",
    "      \"Diversity Spark:\\t%f\" % eval_diversity,\n",
    "      \"Novelty Spark:\\t%f\" % eval_novelty, sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsyskernel",
   "language": "python",
   "name": "recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
