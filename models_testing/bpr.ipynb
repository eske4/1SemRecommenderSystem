{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Personalized Ranking (BPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manuel-albino/miniconda3/envs/recsys/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.9.20 (main, Oct  3 2024, 07:27:41) \n",
      "[GCC 11.2.0]\n",
      "Cornac version: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/06 23:10:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/11/06 23:10:43 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cornac\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "from recommenders.evaluation.python_evaluation import map, ndcg_at_k, precision_at_k, recall_at_k, diversity, novelty, serendipity, catalog_coverage, distributional_coverage\n",
    "from recommenders.models.cornac.cornac_utils import predict_ranking, predict\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.utils.constants import SEED\n",
    "\n",
    "print(f\"System version: {sys.version}\")\n",
    "print(f\"Cornac version: {cornac.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Model parameters\n",
    "NUM_FACTORS = 200\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "# Column names for the dataset\n",
    "COL_USER = \"user_id\"\n",
    "COL_TRACK = \"track_id\"\n",
    "COL_COUNT = \"playcount\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and split data\n",
    "\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_ratings = pd.read_csv(header=0, delimiter=\"\\t\", filepath_or_buffer=\"../remappings/data/Modified_Listening_History.txt\")\n",
    "\n",
    "track = song_ratings[COL_TRACK]\n",
    "user = song_ratings[COL_USER]\n",
    "\n",
    "song_ratings[COL_TRACK] = user\n",
    "song_ratings[COL_USER] = track\n",
    "\n",
    "song_ratings.columns = [COL_USER, COL_TRACK, COL_COUNT]\n",
    "\n",
    "data = song_ratings.sample(frac= 0.001, replace=False, random_state=0)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_random_split(data, 0.75)\n",
    "\n",
    "# Set the alpha value for the confidence transformation\n",
    "alpha = 1\n",
    "\n",
    "# Transform playcount to confidence in the training data only\n",
    "train[\"confidence\"] = 1 + alpha * np.log(1 + train[COL_COUNT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Cornac Dataset\n",
    "\n",
    "To work with models implemented in Cornac, we need to construct an object from [Dataset](https://cornac.readthedocs.io/en/latest/data.html#module-cornac.data.dataset) class.\n",
    "\n",
    "Dataset Class in Cornac serves as the main object that the models will interact with.  In addition to data transformations, Dataset provides a bunch of useful iterators for looping through the data, as well as supporting different negative sampling techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = cornac.data.Dataset.from_uir(train.itertuples(index=False), seed=SEED)\n",
    "\n",
    "print('Number of users: {}'.format(train_set.num_users))\n",
    "print('Number of items: {}'.format(train_set.num_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the BPR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr = cornac.models.BPR(\n",
    "    k=NUM_FACTORS,\n",
    "    max_iter=NUM_EPOCHS,\n",
    "    learning_rate=0.01,\n",
    "    lambda_reg=0.001,\n",
    "    verbose=True,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    bpr.fit(train_set)\n",
    "print(\"Took {} seconds for training.\".format(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    all_predictions = predict_ranking(bpr, train, usercol=COL_USER, itemcol=COL_TRACK, remove_seen=True)\n",
    "print(\"Took {} seconds for prediction.\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by 'user_id' and 'prediction' in descending order\n",
    "all_prediction_sorted = all_predictions.sort_values(by=['user_id', 'prediction'], ascending=[True, False])\n",
    "\n",
    "# Select the top k predictions for each user\n",
    "top_k_rec = all_prediction_sorted.groupby('user_id').head(TOP_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "eval_map = map(test, all_predictions, col_user=COL_USER, col_item=COL_TRACK, col_prediction='prediction', k=k)\n",
    "eval_ndcg = ndcg_at_k(test, all_predictions, col_user=COL_USER, col_item=COL_TRACK, col_rating=COL_COUNT, col_prediction='prediction', k=k)\n",
    "eval_precision = precision_at_k(test, all_predictions, col_user=COL_USER, col_item=COL_TRACK, col_prediction='prediction', k=k)\n",
    "eval_recall = recall_at_k(test, all_predictions, col_user=COL_USER, col_item=COL_TRACK, col_prediction='prediction', k=k)\n",
    "eval_diversity = diversity(\n",
    "    train_df=train,\n",
    "    reco_df=top_k_rec,\n",
    "    col_user=COL_USER,\n",
    "    col_item=COL_TRACK\n",
    ")\n",
    "eval_novelty = novelty(\n",
    "    train_df=train,\n",
    "    reco_df=top_k_rec,\n",
    "    col_user=COL_USER,\n",
    "    col_item=COL_TRACK\n",
    ")\n",
    "# missing serendipity, catalog_coverage and distributional_coverage to be equal to the als metrics\n",
    "# may be incorrect\n",
    "\n",
    "# Print evaluation metrics, including diversity\n",
    "print(\"MAP:\\t%f\" % eval_map,\n",
    "      \"NDCG:\\t%f\" % eval_ndcg,\n",
    "      \"Precision@K:\\t%f\" % eval_precision,\n",
    "      \"Recall@K:\\t%f\" % eval_recall,\n",
    "      \"Diversity:\\t%f\" % eval_diversity,\n",
    "      \"Novelty:\\t%f\" % eval_novelty, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predicted ratings.\n",
    "prediction = predict(bpr, test, usercol=COL_USER, itemcol=COL_TRACK)\n",
    "prediction.cache().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsyskernel",
   "language": "python",
   "name": "recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
