{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Personalized Ranking (BPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cornac\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "from recommenders.evaluation.python_evaluation import map, ndcg_at_k, precision_at_k, recall_at_k, diversity, novelty, serendipity, catalog_coverage, distributional_coverage\n",
    "from recommenders.models.cornac.cornac_utils import predict_ranking, predict\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.utils.constants import SEED\n",
    "\n",
    "#from lenskit.metrics.topn import ndcg, precision, recall\n",
    "\n",
    "print(f\"System version: {sys.version}\")\n",
    "print(f\"Cornac version: {cornac.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 50\n",
    "\n",
    "# Model parameters\n",
    "NUM_FACTORS = 200\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "# Column names for the dataset\n",
    "COL_USER = \"user\"\n",
    "COL_TRACK = \"item\"\n",
    "COL_COUNT = \"playcount\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and split data\n",
    "\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "test_listening_history = pd.read_csv(header=0, delimiter=\"\\t\", filepath_or_buffer=\"../remappings/data/dataset/test_listening_history_OverEqual_50_Interactions.txt\")\n",
    "train_listening_history = pd.read_csv(header=0, delimiter=\"\\t\", filepath_or_buffer=\"../remappings/data/dataset/train_listening_history_OverEqual_50_Interactions.txt\")\n",
    "\n",
    "# Change columns to correct place (user_id, track_id, playcount)\n",
    "track_test = test_listening_history[\"track_id\"]\n",
    "user_test = test_listening_history[\"user_id\"]\n",
    "\n",
    "track_train = train_listening_history[\"track_id\"]\n",
    "user_train = train_listening_history[\"user_id\"]\n",
    "\n",
    "test_listening_history[\"track_id\"] = user_test\n",
    "test_listening_history[\"user_id\"] = track_test\n",
    "\n",
    "train_listening_history[\"track_id\"] = user_train\n",
    "train_listening_history[\"user_id\"] = track_train\n",
    "\n",
    "\n",
    "test_listening_history.columns = [COL_USER, COL_TRACK, COL_COUNT]\n",
    "train_listening_history.columns = [COL_USER, COL_TRACK, COL_COUNT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_listening_history, test_listening_history\n",
    "\n",
    "# Set the alpha value for the confidence transformation\n",
    "alpha = 1\n",
    "\n",
    "# Transform playcount to confidence in the training data only\n",
    "train[\"confidence\"] = 1 + alpha * np.log(1 + train[COL_COUNT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Cornac Dataset\n",
    "\n",
    "To work with models implemented in Cornac, we need to construct an object from [Dataset](https://cornac.readthedocs.io/en/latest/data.html#module-cornac.data.dataset) class.\n",
    "\n",
    "Dataset Class in Cornac serves as the main object that the models will interact with.  In addition to data transformations, Dataset provides a bunch of useful iterators for looping through the data, as well as supporting different negative sampling techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = cornac.data.Dataset.from_uir(train.itertuples(index=False), seed=SEED)\n",
    "\n",
    "print('Number of users: {}'.format(train_set.num_users))\n",
    "print('Number of items: {}'.format(train_set.num_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the BPR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr = cornac.models.BPR(\n",
    "    k=NUM_FACTORS,\n",
    "    max_iter=NUM_EPOCHS,\n",
    "    learning_rate=0.01,\n",
    "    lambda_reg=0.001,\n",
    "    verbose=True,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    bpr.fit(train_set)\n",
    "print(\"Took {} seconds for training.\".format(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    all_predictions = predict_ranking(bpr, train, usercol=COL_USER, itemcol=COL_TRACK, remove_seen=True)\n",
    "print(\"Took {} seconds for prediction.\".format(t))\n",
    "\n",
    "all_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by 'user' and 'prediction' in descending order\n",
    "all_prediction_sorted = all_predictions.sort_values(by=[COL_USER, 'prediction'], ascending=[True, False])\n",
    "\n",
    "# Select the top k predictions for each user\n",
    "top_k_rec = all_prediction_sorted.groupby(COL_USER).head(TOP_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_map = map(test, all_predictions, col_user=COL_USER, col_item=COL_TRACK, col_prediction='prediction', k=TOP_K)\n",
    "eval_ndcg = ndcg_at_k(test, all_predictions, col_user=COL_USER, col_item=COL_TRACK, col_rating=COL_COUNT, col_prediction='prediction', k=TOP_K)\n",
    "eval_precision = precision_at_k(test, all_predictions, col_user=COL_USER, col_item=COL_TRACK, col_prediction='prediction', k=TOP_K)\n",
    "eval_recall = recall_at_k(test, all_predictions, col_user=COL_USER, col_item=COL_TRACK, col_prediction='prediction', k=TOP_K)\n",
    "eval_diversity = diversity(\n",
    "    train_df=train,\n",
    "    reco_df=top_k_rec,\n",
    "    col_user=COL_USER,\n",
    "    col_item=COL_TRACK\n",
    ")\n",
    "eval_novelty = novelty(\n",
    "    train_df=train,\n",
    "    reco_df=top_k_rec,\n",
    "    col_user=COL_USER,\n",
    "    col_item=COL_TRACK\n",
    ")\n",
    "# missing serendipity, catalog_coverage and distributional_coverage to be equal to the als metrics\n",
    "# may be incorrect\n",
    "\n",
    "# Print evaluation metrics, including diversity\n",
    "print(\"Precision@K Spark:\\t%f\" % eval_precision,\n",
    "      \"Recall@K Spark:\\t%f\" % eval_recall,\n",
    "      \"NDCG Spark:\\t%f\" % eval_ndcg,\n",
    "      \"Diversity Spark:\\t%f\" % eval_diversity,\n",
    "      \"Novelty Spark:\\t%f\" % eval_novelty, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_ndcg_lens = ndcg(all_predictions, test, k=TOP_K)\n",
    "# eval_precision_lens = precision(all_predictions, test, k=TOP_K)\n",
    "# eval_recall_lens = recall(all_predictions, test, k=TOP_K)\n",
    "\n",
    "# # Print evaluation metrics, including diversity\n",
    "# print(\"Precision@K Lenskit:\\t%f\" % eval_precision_lens,\n",
    "#       \"Recall@K Lenskit:\\t%f\" % eval_recall_lens,\n",
    "#       \"NDCG Lenskit:\\t%f\" % eval_ndcg_lens, sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsyskernel",
   "language": "python",
   "name": "recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
