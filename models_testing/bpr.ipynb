{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Personalized Ranking (BPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cornac\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from recommenders.evaluation.python_evaluation import map, ndcg_at_k, precision_at_k, recall_at_k, diversity, novelty\n",
    "from recommenders.models.cornac.cornac_utils import predict_ranking\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.utils.constants import SEED\n",
    "\n",
    "print(f\"System version: {sys.version}\")\n",
    "print(f\"Cornac version: {cornac.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 50\n",
    "\n",
    "# Model parameters\n",
    "NUM_FACTORS = 200\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "# Column names for the dataset\n",
    "COL_USER = \"user_id\"\n",
    "COL_TRACK = \"track_id\"\n",
    "COL_COUNT = \"playcount\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and split data\n",
    "\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "test_listening_history = pd.read_csv(header=0, delimiter=\"\\t\", filepath_or_buffer=\"../remappings/data/dataset/test_listening_history_OverEqual_50_Interactions.txt\")\n",
    "train_listening_history = pd.read_csv(header=0, delimiter=\"\\t\", filepath_or_buffer=\"../remappings/data/dataset/train_listening_history_OverEqual_50_Interactions.txt\")\n",
    "\n",
    "# Change columns to correct place (user_id, track_id, playcount)\n",
    "track_test = test_listening_history[\"track_id\"]\n",
    "user_test = test_listening_history[\"user_id\"]\n",
    "\n",
    "track_train = train_listening_history[\"track_id\"]\n",
    "user_train = train_listening_history[\"user_id\"]\n",
    "\n",
    "test_listening_history[\"track_id\"] = user_test\n",
    "test_listening_history[\"user_id\"] = track_test\n",
    "\n",
    "train_listening_history[\"track_id\"] = user_train\n",
    "train_listening_history[\"user_id\"] = track_train\n",
    "\n",
    "test_listening_history.columns = [COL_USER, COL_TRACK, COL_COUNT]\n",
    "train_listening_history.columns = [COL_USER, COL_TRACK, COL_COUNT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_listening_history, test_listening_history\n",
    "\n",
    "# Set the alpha value for the confidence transformation\n",
    "alpha = 1\n",
    "\n",
    "# Transform playcount to confidence in the training data only\n",
    "train[\"confidence\"] = 1 + alpha * np.log(1 + train[COL_COUNT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Cornac Dataset\n",
    "\n",
    "To work with models implemented in Cornac, we need to construct an object from [Dataset](https://cornac.readthedocs.io/en/latest/data.html#module-cornac.data.dataset) class.\n",
    "\n",
    "Dataset Class in Cornac serves as the main object that the models will interact with.  In addition to data transformations, Dataset provides a bunch of useful iterators for looping through the data, as well as supporting different negative sampling techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = cornac.data.Dataset.from_uir(train.itertuples(index=False), seed=SEED)\n",
    "\n",
    "print('Number of users: {}'.format(train_set.num_users))\n",
    "print('Number of items: {}'.format(train_set.num_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the BPR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr = cornac.models.BPR(\n",
    "    k=NUM_FACTORS,\n",
    "    max_iter=NUM_EPOCHS,\n",
    "    learning_rate=0.01,\n",
    "    lambda_reg=0.001,\n",
    "    verbose=True,\n",
    "    seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    bpr.fit(train_set)\n",
    "print(\"Took {} seconds for training.\".format(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    all_predictions = predict_ranking(bpr, train, usercol=COL_USER, itemcol=COL_TRACK, remove_seen=True)\n",
    "print(\"Took {} seconds for prediction.\".format(t))\n",
    "\n",
    "all_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by 'user' and 'prediction' in descending order\n",
    "all_prediction_sorted = all_predictions.sort_values(by=[COL_USER, 'prediction'], ascending=[True, False])\n",
    "\n",
    "# Select the top k predictions for each user\n",
    "top_k_rec = all_prediction_sorted.groupby(COL_USER).head(TOP_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_map = map(test, top_k_rec, \n",
    "               col_user=COL_USER, \n",
    "               col_item=COL_TRACK, \n",
    "               col_prediction='prediction', \n",
    "               k=TOP_K,\n",
    "               relevancy_method=None)\n",
    "\n",
    "eval_ndcg = ndcg_at_k(test, top_k_rec, \n",
    "                      col_user=COL_USER, \n",
    "                      col_item=COL_TRACK, \n",
    "                      col_rating=COL_COUNT, \n",
    "                      col_prediction='prediction', \n",
    "                      k=TOP_K, \n",
    "                      relevancy_method=None)\n",
    "\n",
    "eval_precision = precision_at_k(test, top_k_rec, \n",
    "                                col_user=COL_USER, \n",
    "                                col_item=COL_TRACK, \n",
    "                                col_prediction='prediction', \n",
    "                                k=TOP_K, \n",
    "                                relevancy_method=None)\n",
    "\n",
    "eval_recall = recall_at_k(test, top_k_rec, \n",
    "                          col_user=COL_USER, \n",
    "                          col_item=COL_TRACK, \n",
    "                          col_prediction='prediction', \n",
    "                          k=TOP_K, \n",
    "                          relevancy_method=None)\n",
    "\n",
    "eval_diversity = diversity(train_df=train,\n",
    "                           reco_df=top_k_rec,\n",
    "                           col_user=COL_USER,\n",
    "                           col_item=COL_TRACK)\n",
    "\n",
    "eval_novelty = novelty(train_df=train,\n",
    "                       reco_df=top_k_rec,\n",
    "                       col_user=COL_USER,\n",
    "                       col_item=COL_TRACK)\n",
    "\n",
    "# Print evaluation metrics, including diversity\n",
    "print(\"Precision@K Spark:\\t%f\" % eval_precision,\n",
    "      \"Recall@K Spark:\\t%f\" % eval_recall,\n",
    "      \"NDCG Spark:\\t%f\" % eval_ndcg,\n",
    "      \"Diversity Spark:\\t%f\" % eval_diversity,\n",
    "      \"Novelty Spark:\\t%f\" % eval_novelty, sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsyskernel",
   "language": "python",
   "name": "recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
